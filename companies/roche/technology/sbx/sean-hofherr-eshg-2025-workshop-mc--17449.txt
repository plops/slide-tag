Extracting audio from 'sean-hofherr-eshg-2025-workshop-mc--17449'...
Transcribing audio to text...

[00:00:00.660 --> 00:00:02.400]   Thanks for the intro, me too.
[00:00:02.400 --> 00:00:05.660]   Thanks for also, like, walking through my whole CV.
[00:00:05.660 --> 00:00:06.200]   That was great.
[00:00:06.200 --> 00:00:12.740]   So I'm going to talk to you guys about pretty much adding on to what Mark talked about.
[00:00:12.740 --> 00:00:20.260]   We've been focusing a lot at Broad on trying to have not just proof of principle that this
[00:00:20.260 --> 00:00:24.860]   technology can work, but how do we actually start thinking about this in practice, especially
[00:00:24.860 --> 00:00:25.880]   in the clinical space.
[00:00:26.840 --> 00:00:32.540]   So Broad Clinical Labs, we're a part of the Broad Institute, also known as the genomics
[00:00:32.540 --> 00:00:37.400]   platform within the Broad Institute, really large sequencing center in the U.S., based
[00:00:37.400 --> 00:00:38.560]   in Cambridge, Massachusetts.
[00:00:38.560 --> 00:00:46.200]   We serve quite a lot of different groups that span across different types of partners.
[00:00:46.200 --> 00:00:51.640]   So we have some groups that are, like, really trying to push the boundaries of genomics.
[00:00:51.640 --> 00:01:01.040]   So how do you do, identify new types of events, add new technologies, really, like, the people
[00:01:01.040 --> 00:01:04.060]   who are kind of creating the groundbreaking research.
[00:01:04.060 --> 00:01:07.420]   We then also have a lot of groups that are doing, like, resource building.
[00:01:07.420 --> 00:01:12.980]   So a lot of the tools that a lot of people in this room end up using actually come out
[00:01:12.980 --> 00:01:17.680]   of the Broad Institute, and also we're a part of, like, large consortia.
[00:01:17.680 --> 00:01:21.140]   So we generate a lot of data, and we make a lot of that data publicly available.
[00:01:21.140 --> 00:01:23.540]   And then the last group are really clinical translators.
[00:01:23.540 --> 00:01:29.700]   So this is kind of a newer arm of Broad Institute, and that's where our group primarily focuses.
[00:01:29.700 --> 00:01:36.180]   And how do we take this technology and these large data sets and our scale and actually apply
[00:01:36.180 --> 00:01:37.560]   them to clinical problems?
[00:01:37.560 --> 00:01:43.260]   So here's a couple of the different partners that we have in the different groups, and some
[00:01:43.260 --> 00:01:44.540]   of these may be familiar to you.
[00:01:44.540 --> 00:01:49.620]   Most of them are based in the U.S., so recognize them that this is international community.
[00:01:49.820 --> 00:01:51.360]   So some of them may not be familiar.
[00:01:51.360 --> 00:01:55.580]   So we are a large-scale sequencing center.
[00:01:55.580 --> 00:01:57.740]   So this is just looking at our current fleet.
[00:01:57.740 --> 00:02:04.040]   So we have a large setup of NovaSeq X Pluses that are pretty much running nonstop around the
[00:02:04.040 --> 00:02:04.340]   clock.
[00:02:04.340 --> 00:02:09.080]   We have several of the Ultima systems and then 10 PacBio Revios.
[00:02:09.080 --> 00:02:14.640]   On the right-hand side, you can see some of our midplex and smaller sequencers as well.
[00:02:14.640 --> 00:02:19.800]   So we're pretty much platform agnostic, and we actually really like to have the opportunity
[00:02:19.800 --> 00:02:25.060]   to engage with vendors as they're first working on their technology.
[00:02:25.060 --> 00:02:30.740]   So we tend to be like a proving ground for a lot of new technologies, which is a really
[00:02:30.740 --> 00:02:31.400]   great opportunity.
[00:02:31.400 --> 00:02:36.360]   And that's actually kind of how the conversation with Roche started, I guess about like pretty
[00:02:36.360 --> 00:02:40.700]   much a year and a couple months ago was when the first conversations were taking place.
[00:02:40.700 --> 00:02:45.500]   And in those conversations, the Roche team, like Mark kind of went through a lot of the
[00:02:45.500 --> 00:02:51.520]   initial data, had some pretty impressive claims on the ability of the sequencer to have high
[00:02:51.520 --> 00:02:54.300]   accuracy, high speed, and high scale.
[00:02:55.140 --> 00:03:06.080]   So basically having the ability to have a lot of runs, smaller runs and smaller batch sizes, leads to actually a huge amount of scale that could come out of one
[00:03:06.080 --> 00:03:06.660]   sequencer.
[00:03:06.660 --> 00:03:12.400]   The Nanopore and Expandimer sequencer has a lot of potential with accuracy, as Mark talked about.
[00:03:12.400 --> 00:03:16.780]   And so it was great to hear about all this.
[00:03:16.780 --> 00:03:21.320]   And so we were kind of thinking about what the applications are for this technology.
[00:03:21.320 --> 00:03:29.580]   So what are those different aspects and different things that the sequencer is really good and the SBX chemistry is really good for?
[00:03:29.580 --> 00:03:31.540]   What are the best applications for this?
[00:03:31.540 --> 00:03:37.780]   And so I immediately started thinking about rapid genome in the neonatal intensive care unit.
[00:03:37.780 --> 00:03:42.380]   And so this is a figure from a publication that came out of Stephen Kingsmore's group.
[00:03:42.380 --> 00:03:56.900]   But in general, the ability to have early diagnostic testing by rapid whole genome ends up saving a significant amount of burden on the patient, the healthcare system, the hospitals.
[00:03:56.900 --> 00:04:00.780]   Around 60% of the patients end up with positive findings.
[00:04:00.780 --> 00:04:13.140]   So the NICU, even patients that you don't expect to have monogenic genetic conditions, once you actually start testing, you end up seeing that there's a large percentage of these patients that have it.
[00:04:13.140 --> 00:04:19.600]   There's not always, as we all know, like for monogenic conditions, there's not always therapeutic intervention.
[00:04:19.600 --> 00:04:21.900]   Now there's more and more that are hitting the market.
[00:04:21.900 --> 00:04:32.460]   But even just having an answer helps a lot with the management and management decisions, both for like the neonatal team and for the parents of this child who's severely sick.
[00:04:32.460 --> 00:04:36.580]   And so being able to get an answer fast is critical.
[00:04:36.580 --> 00:04:38.780]   And people have been doing this.
[00:04:38.780 --> 00:04:46.860]   So rapid NICU genome testing has been around since, I don't know, probably around 2015, 2014.
[00:04:46.860 --> 00:04:54.380]   And RADIs has really been kind of championing this in the US, and then, and other groups have as well.
[00:04:54.380 --> 00:04:57.420]   And now there's commercial offerings for rapid testing.
[00:04:57.420 --> 00:05:00.140]   However, that rapid testing, it still takes a while.
[00:05:00.140 --> 00:05:05.540]   So rapid could be anywhere from a week, it could be four days.
[00:05:05.540 --> 00:05:12.100]   Now I've seen an advertisement for like an ultra rapid 72 hours, which is great.
[00:05:12.100 --> 00:05:22.100]   But every single day that you don't have a diagnosis or every hour that you don't have a diagnosis in these patients, actually, it's a pretty big burden on the family and the healthcare team.
[00:05:22.100 --> 00:05:28.660]   So we got the system in January, and we presented some of this work at AGBT.
[00:05:28.660 --> 00:05:38.660]   And initially, when we first got the, so we got it shortly after holiday break, got set up in our lab really quickly, within a week we were generating data.
[00:05:38.660 --> 00:05:49.780]   And in some of the initial training runs, we were trying out the workflow, we weren't really like focusing too much on speed, although we wanted to be, try to keep it as quick as possible.
[00:05:49.780 --> 00:05:55.300]   And we were able to get it down to 12 hours and 10 minutes, which is great, like that was great.
[00:05:55.300 --> 00:05:58.580]   So this is three samples at a time being run.
[00:05:58.580 --> 00:06:09.300]   Here you can see just like looking at the quality scores between HE001 through HE004, Mark presented a lot of this, I'm not going to go into details, but like the overall performance is really good.
[00:06:09.300 --> 00:06:18.580]   Mark also showed this in kind of a different way, but just looking at performance, this is focused on SMVs, but the same thing holds true for indels.
[00:06:18.580 --> 00:06:22.900]   If you look at the homopolymers and high GC, low GC, it performs really well.
[00:06:25.300 --> 00:06:32.900]   So we took some of this same approach and we started testing first patient cell lines.
[00:06:32.900 --> 00:06:39.140]   So we were looking at patients with different conditions, oftentimes that would be diagnosed in the neonatal period.
[00:06:39.140 --> 00:06:48.340]   So there's quite a few inborn errors of metabolism that are here and, and we were able in all the cases to detect the causative variant or variants.
[00:06:48.340 --> 00:06:55.060]   And so you'd see there's a list of small variant tests that we did, large copy number event cases.
[00:06:55.300 --> 00:07:02.020]   And then repeat expansions also using some of the Roche developed bioinformatic solutions for repeat expansions.
[00:07:02.020 --> 00:07:05.300]   We were able to detect all of these causative findings.
[00:07:05.300 --> 00:07:12.500]   We then took the, that same approach and tested some previously diagnosed patients in our laboratory, in our clinical lab.
[00:07:12.500 --> 00:07:18.100]   And this is just like patients that were tested and run by our standard 30X genome.
[00:07:18.100 --> 00:07:22.100]   And we were able to, to find the causative variant in all those cases.
[00:07:22.100 --> 00:07:29.540]   And so all this work, like I said, was presented at AGBT and it was all generated in January.
[00:07:29.540 --> 00:07:32.100]   Mark kind of showed a little bit of this.
[00:07:32.100 --> 00:07:39.940]   So this was kind of like the, the starting point of, you know, we have a really fast assay, but how fast can it be?
[00:07:39.940 --> 00:07:48.340]   And like, this was, this was like in February, right before the conference, we got it down to six hours and 25 minutes, which is absolutely amazing.
[00:07:48.340 --> 00:07:49.540]   This is just one sample.
[00:07:49.540 --> 00:07:49.860]   Okay.
[00:07:49.860 --> 00:07:52.020]   So like a single sample going through the workflow.
[00:07:52.020 --> 00:07:54.500]   Mark showed now we could do it two hours less.
[00:07:54.500 --> 00:07:56.820]   So four hours and 25 minutes, which is nuts.
[00:07:56.820 --> 00:08:05.700]   Still one sample when we think about it, as I said, like our goal is not, how do we show the fastest genome?
[00:08:05.700 --> 00:08:08.100]   We are interested in showing the fastest genome.
[00:08:08.100 --> 00:08:15.540]   So I don't mean to say that this is not of interest, but when we think about like productionization and actually running on a very routine basis,
[00:08:15.540 --> 00:08:20.180]   we want to run something that's going to be able to actually like handle the needs of the clinic.
[00:08:20.180 --> 00:08:27.380]   And so for rapid genome, the most useful approach would be, would be testing a three sample set.
[00:08:27.380 --> 00:08:31.460]   Because you could have like mom, dad and probands.
[00:08:31.460 --> 00:08:35.380]   And that could be really, really informative when you're thinking about variants and inheritance.
[00:08:35.380 --> 00:08:36.660]   Is it a de novo variant?
[00:08:36.660 --> 00:08:38.340]   Was it inherited from a healthy parent?
[00:08:38.340 --> 00:08:43.780]   All these things are like really, really useful when determining the significance of a variant.
[00:08:44.180 --> 00:08:49.860]   And so when we started after the conference, we spent some time.
[00:08:49.860 --> 00:08:53.780]   A lot of the work was done in the Seattle group from Roche.
[00:08:53.780 --> 00:09:00.820]   But then like taking this technology and actually applying it in our hands, we were able to get three samples.
[00:09:00.820 --> 00:09:07.380]   So three whole genomes going from DNA through variants in a really aggressive time.
[00:09:07.380 --> 00:09:11.940]   So it was like eight hours and two minutes for three genomes to be sequenced, which is great.
[00:09:11.940 --> 00:09:14.420]   We even got one to be below the eight hour time point.
[00:09:14.420 --> 00:09:18.100]   We were like ecstatic, fantastic.
[00:09:18.100 --> 00:09:24.500]   And then we kind of added some more tweaks in.
[00:09:24.500 --> 00:09:26.260]   So this is a constant iterative process.
[00:09:26.260 --> 00:09:31.540]   And now we got it down to seven hours and eight minutes for three samples being sequenced at the same time.
[00:09:31.540 --> 00:09:33.620]   So this is two separate runs of trios.
[00:09:33.620 --> 00:09:37.540]   Just to show that like consistently, we're getting over 30x.
[00:09:37.540 --> 00:09:44.020]   Consistently, we're getting our time to be in this like really, really amazing time frame to be able to sequence genomes.
[00:09:44.020 --> 00:09:50.100]   We wanted to see, you know, it's great to have a fast genome.
[00:09:50.100 --> 00:09:53.140]   But can we actually detect causative variants in patients?
[00:09:53.140 --> 00:09:56.260]   So we tested another group of cell lines.
[00:09:56.260 --> 00:09:58.580]   Some of these are the same ones, but a lot of them are different.
[00:09:59.460 --> 00:10:01.380]   Also looking at small variants.
[00:10:01.380 --> 00:10:05.860]   A lot of these are inborn errors of metabolism and other conditions that present in the neonatal period.
[00:10:05.860 --> 00:10:07.380]   Not all of them are, but most of them are.
[00:10:07.380 --> 00:10:12.900]   We looked at large copy number events and we also looked at repeat expansion.
[00:10:12.900 --> 00:10:15.460]   For all these, we were able to detect the causative variant again.
[00:10:15.460 --> 00:10:19.380]   So we're not just getting really fast sequencing and really accurate sequencing.
[00:10:19.380 --> 00:10:23.620]   We're actually able to find diagnostic hits in cases.
[00:10:23.620 --> 00:10:24.980]   So these are a set of cell lines.
[00:10:24.980 --> 00:10:29.140]   And this is just like looking at some of the data.
[00:10:29.140 --> 00:10:31.620]   So the data looks really clean and really nice.
[00:10:31.620 --> 00:10:36.820]   So this is a single nucleotide variant for Usher syndrome patients.
[00:10:36.820 --> 00:10:40.500]   This is looking at cystic fibrosis, looking at a heterozygous call.
[00:10:40.500 --> 00:10:41.300]   Looks really nice.
[00:10:42.660 --> 00:10:47.060]   This is a single, so this is a base deletion.
[00:10:47.060 --> 00:10:49.300]   I guess a three base deletion is cystic fibrosis.
[00:10:49.300 --> 00:10:54.820]   So this is the classic Delta F508 variant that's like super common in Northern Europe.
[00:10:54.820 --> 00:11:00.100]   Homozygous single base pair deletion.
[00:11:00.100 --> 00:11:03.940]   So you'd notice a lot of the propionic acidemia cases like Mark showed it too.
[00:11:03.940 --> 00:11:08.180]   This is great because it's like my kind of pet disease of interest.
[00:11:08.180 --> 00:11:09.460]   And so I keep plugging it.
[00:11:09.460 --> 00:11:13.940]   And so that's why there's a lot of PCCA and PCCB samples getting tested.
[00:11:13.940 --> 00:11:21.060]   This is just, you know, another example of a complex insertion deletion.
[00:11:21.060 --> 00:11:26.340]   So this is in the second subunit of the propionic acidemia, propionyl-CoA carboxylase gene, PCCB.
[00:11:26.340 --> 00:11:29.780]   In all these cases, the data is really clean.
[00:11:29.780 --> 00:11:32.020]   And it looks great.
[00:11:32.020 --> 00:11:36.740]   And these are not just like looking for events in IGV, although that's what I'm showing.
[00:11:36.740 --> 00:11:39.220]   These are actually calls that are being made in the VCF.
[00:11:39.220 --> 00:11:46.340]   This is looking at a copy number event in the Duchenne muscular dystrophy gene, DMD.
[00:11:46.340 --> 00:11:48.900]   This is a patient who has Becker muscular dystrophy.
[00:11:48.900 --> 00:11:51.140]   And we're able to find the causative event here too.
[00:11:51.140 --> 00:11:53.540]   There are a bunch of other examples too.
[00:11:53.540 --> 00:11:56.100]   I'm not going to go into many more.
[00:11:56.100 --> 00:11:59.620]   Just to show we were able to identify a repeat expansion.
[00:11:59.620 --> 00:12:02.820]   So this is looking at a patient that has Friedrich's ataxia.
[00:12:02.820 --> 00:12:08.100]   It's an autosomal recessive repeat expansion condition, which is different than a lot of the other repeat expansion conditions.
[00:12:08.100 --> 00:12:14.100]   We were able to see two expansions at different sizes that are in the full expansion range.
[00:12:14.100 --> 00:12:17.300]   So really cool to be able to see all these different use cases.
[00:12:19.780 --> 00:12:28.980]   When we're testing patients, we don't really go into the VCF file, nor do we typically go searching around for things in IGV.
[00:12:28.980 --> 00:12:31.700]   We oftentimes will use tertiary analysis software.
[00:12:31.700 --> 00:12:36.340]   And so great to see that things are detected in the VCF.
[00:12:36.340 --> 00:12:37.940]   Great to see that we're able to see the variant.
[00:12:37.940 --> 00:12:42.660]   But are we actually able to identify and prioritize variants in cases?
[00:12:43.540 --> 00:12:53.140]   So looking at a sample, once again, propionic acidemia sample, this is a trio where you have both parents are heterozygous carriers.
[00:12:53.140 --> 00:12:58.180]   And then the proband is homozygous for this single base pair deletion.
[00:12:58.180 --> 00:13:05.780]   This is using the platform that we use clinically at Broad Clinical Labs, which is fabric genomics, fabric enterprise system.
[00:13:06.580 --> 00:13:10.260]   And we're able to see the causative variant that was prioritized all the way at the top.
[00:13:10.260 --> 00:13:11.620]   Very high score.
[00:13:11.620 --> 00:13:16.340]   And once again, this is not being used for clinical use.
[00:13:16.340 --> 00:13:22.980]   But if it was being used for clinical use, the next step would be basically the creation of the clinical report also able to be done.
[00:13:22.980 --> 00:13:25.140]   This was more like proof of principle.
[00:13:25.140 --> 00:13:30.900]   Can we take a sample and the VCF and load it into tertiary analysis platform?
[00:13:32.100 --> 00:13:38.500]   We did this kind of like under the radar without even telling fabric or really anybody else that we were going to do it.
[00:13:38.500 --> 00:13:41.220]   And and it worked, which is great.
[00:13:41.220 --> 00:13:46.500]   So it performs very similar to to like other short read technologies like Mark showed.
[00:13:46.500 --> 00:13:51.620]   It's especially when we're looking at the fast, it's the read lengths are comparable.
[00:13:51.620 --> 00:13:54.260]   They're a little bit longer in this duplex format.
[00:13:54.900 --> 00:13:58.340]   But but overall, it's able to kind of come into different tertiary platforms.
[00:13:58.340 --> 00:14:04.820]   So obviously, like we've done a lot in the last, I don't know, two or three months.
[00:14:04.820 --> 00:14:09.220]   And in the last five or six months, we've done quite a lot.
[00:14:09.220 --> 00:14:11.700]   But there's still a lot of work to do.
[00:14:11.700 --> 00:14:14.340]   And so Mark kind of alluded to this earlier.
[00:14:14.340 --> 00:14:20.500]   We have this collaboration agreement that was announced between our group at Broad Clinical Labs and Roche sequencing team.
[00:14:21.220 --> 00:14:25.220]   And a lot of the work that we're focusing on for this part of the project is really like,
[00:14:25.220 --> 00:14:28.260]   how do we take this from concept?
[00:14:28.260 --> 00:14:34.500]   How do we continue to optimize the bioinformatics for these complex genes and variant types, which is really important?
[00:14:35.940 --> 00:14:38.500]   We have to we really have to like streamline this.
[00:14:38.500 --> 00:14:43.700]   So like it's it's fast and easy, but it still takes a person to do it right now.
[00:14:43.700 --> 00:14:46.900]   And so we'd like to get to automation whenever it's beneficial.
[00:14:46.900 --> 00:14:50.260]   We showed one example of tertiary analysis.
[00:14:50.260 --> 00:14:55.300]   But there's as you can see at this conference, there's like a gazillion different tertiary analysis vendors.
[00:14:55.300 --> 00:15:00.180]   And it'd be great to kind of see how this performs in lots of different tertiary analysis platforms,
[00:15:00.180 --> 00:15:07.220]   as well as giving vendors the opportunity to potentially tune their their AI and algorithms so that it could detect the causative variance.
[00:15:07.220 --> 00:15:11.540]   Because like I said, we did this with Fabric without them even being aware that we were doing it.
[00:15:11.540 --> 00:15:14.660]   And then validating an end-to-end workflow.
[00:15:14.660 --> 00:15:21.220]   And then really like the exciting part for me is taking this idea and starting to implement it for actual patient care.
[00:15:21.220 --> 00:15:26.020]   So pairing up with a partner who's already set up and really interested in this.
[00:15:26.020 --> 00:15:32.580]   How do we get the rapid genome to be done in like one day and one shift?
[00:15:32.580 --> 00:15:35.220]   Which is pretty awesome and kind of unheard of at this point.
[00:15:35.220 --> 00:15:39.540]   So this work very little that was actually done by me.
[00:15:39.540 --> 00:15:43.620]   This is really like the the team that was responsible for all of the work that you saw here.
[00:15:43.620 --> 00:15:48.900]   The picture is the broad team standing in front of our systems.
[00:15:48.900 --> 00:15:50.740]   They don't look as pretty as the ones at the booth.
[00:15:50.740 --> 00:15:52.820]   They're still kind of early alpha release.
[00:15:52.820 --> 00:15:58.660]   And and obviously like this is not just work that we're doing independently.
[00:15:58.660 --> 00:16:02.900]   The Roche team has been hugely helpful and and really like it's a great partnership.
[00:16:02.900 --> 00:16:05.300]   It's kind of rare to interact with
[00:16:05.300 --> 00:16:08.100]   with a group and like a large corporation like Roche that
[00:16:08.100 --> 00:16:11.540]   that with a team that operates very much like a startup.
[00:16:11.540 --> 00:16:16.740]   So I'm pretty sure like Mark's whole team is sleeping in the laboratory and not doing anything except for this.
[00:16:16.740 --> 00:16:17.940]   But but it's great.
[00:16:17.940 --> 00:16:20.660]   So we're constantly pushing the envelope of what's possible.
[00:16:20.660 --> 00:16:24.580]   So thank you.
Transcription complete. Output saved to 'sean-hofherr-eshg-2025-workshop-mc--17449.txt'
Removing intermediate audio file...
Done.
